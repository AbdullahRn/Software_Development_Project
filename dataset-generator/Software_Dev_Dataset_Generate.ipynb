{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "Z6iaW88g-LhB",
        "outputId": "e9b71b9f-657e-4650-b850-494d3a3a11fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to MongoDB Atlas...\n",
            "✅ Connected successfully!\n",
            "\n",
            "Clearing collections...\n",
            "✅ MongoDB cleared successfully.\n",
            "{'category': 0, 'supplier': 0, 'user': 0, 'product': 0, 'transaction': 0}\n",
            "\n",
            "✅ CSV files generated successfully:\n",
            " - generated_csv/categories.csv\n",
            " - generated_csv/suppliers.csv\n",
            " - generated_csv/users.csv\n",
            " - generated_csv/products.csv\n",
            " - generated_csv/transactions.csv\n",
            "\n",
            "Rows generated:\n",
            "categories: 6\n",
            "suppliers: 6\n",
            "users: 16 (includes suppliers + sellers)\n",
            "products: 30\n",
            "transactions: 5387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3833045493.py:138: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"createdAt\": datetime.utcnow().isoformat()\n",
            "/tmp/ipython-input-3833045493.py:152: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"createdAt\": datetime.utcnow().isoformat()\n",
            "/tmp/ipython-input-3833045493.py:184: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"createdAt\": datetime.utcnow().isoformat()\n",
            "/tmp/ipython-input-3833045493.py:229: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"createdAt\": datetime.utcnow().isoformat()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_98723f3c-b5ab-42ea-926a-7b85a1aa0bd9\", \"generated_csv.zip\", 82238)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ===========================\n",
        "# MongoDB Atlas Reset + Correct CSV Generator (Matches Your Models Exactly)\n",
        "# ===========================\n",
        "# ✅ Clears MongoDB Atlas collections\n",
        "# ✅ Generates CSVs that match your Spring Boot models:\n",
        "#    categories.csv, suppliers.csv, users.csv, products.csv, transactions.csv\n",
        "# ✅ Supplier relation fixed:\n",
        "#    - Supplier IDs: SUP1..SUPn\n",
        "#    - Supplier Users: SAME IDs SUP1..SUPn with role=SUPPLIER\n",
        "#    - Product.supplierId references Supplier User IDs (SUP*)\n",
        "#    - PURCHASE transactions supplierId also references SUP*\n",
        "# ✅ Downloads generated_csv.zip\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip -q install pymongo faker pandas numpy\n",
        "\n",
        "# ---------------------------\n",
        "# 1) CONFIG (PASTE YOUR ATLAS URI HERE)\n",
        "# ---------------------------\n",
        "MONGO_URI = \"mongodb+srv://abdullahrn746_db_user:mongo@cluster0.jejibgt.mongodb.net/inventorydb?appName=Cluster0\"\n",
        "DB_NAME   = \"softwaredevelopment\"   # must match spring.data.mongodb.database\n",
        "\n",
        "COLLECTIONS_TO_CLEAR = [\"category\", \"supplier\", \"user\", \"product\", \"transaction\"]\n",
        "OUTPUT_DIR = \"generated_csv\"\n",
        "\n",
        "START_DATE = \"2024-01-01\"\n",
        "END_DATE   = \"2026-01-01\"\n",
        "\n",
        "CATEGORY_COUNT  = 6\n",
        "SUPPLIER_COUNT  = 6\n",
        "SELLER_USER_COUNT = 10\n",
        "PRODUCT_COUNT   = 30\n",
        "\n",
        "TX_PER_DAY_MIN = 3\n",
        "TX_PER_DAY_MAX = 12\n",
        "\n",
        "DEFAULT_PASSWORD = \"123456\"\n",
        "\n",
        "# ---------------------------\n",
        "# 2) IMPORTS\n",
        "# ---------------------------\n",
        "from pymongo import MongoClient\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import random, os\n",
        "\n",
        "fake = Faker()\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 3) CONNECT TO ATLAS\n",
        "# ---------------------------\n",
        "print(\"Connecting to MongoDB Atlas...\")\n",
        "client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=15000)\n",
        "\n",
        "try:\n",
        "    client.admin.command(\"ping\")\n",
        "    print(\"✅ Connected successfully!\")\n",
        "except Exception as e:\n",
        "    raise Exception(\n",
        "        \"❌ Could not connect to MongoDB Atlas.\\n\"\n",
        "        \"Check:\\n\"\n",
        "        \"1) MONGO_URI is correct\\n\"\n",
        "        \"2) Atlas Network Access allows 0.0.0.0/0 for testing\\n\"\n",
        "        \"3) username/password correct\\n\"\n",
        "        f\"\\nOriginal error: {e}\"\n",
        "    )\n",
        "\n",
        "db = client[DB_NAME]\n",
        "\n",
        "# ---------------------------\n",
        "# 4) CLEAR COLLECTIONS\n",
        "# ---------------------------\n",
        "print(\"\\nClearing collections...\")\n",
        "for c in COLLECTIONS_TO_CLEAR:\n",
        "    db[c].delete_many({})\n",
        "\n",
        "print(\"✅ MongoDB cleared successfully.\")\n",
        "print({c: db[c].count_documents({}) for c in COLLECTIONS_TO_CLEAR})\n",
        "\n",
        "# ---------------------------\n",
        "# 5) HELPER IDS\n",
        "# ---------------------------\n",
        "def make_id(prefix, i):\n",
        "    return f\"{prefix}{i}\"\n",
        "\n",
        "category_ids = [make_id(\"CAT\", i) for i in range(1, CATEGORY_COUNT + 1)]\n",
        "supplier_ids = [make_id(\"SUP\", i) for i in range(1, SUPPLIER_COUNT + 1)]\n",
        "seller_user_ids = [make_id(\"USR\", i) for i in range(1, SELLER_USER_COUNT + 1)]\n",
        "product_ids  = [make_id(\"PROD\", i) for i in range(1, PRODUCT_COUNT + 1)]\n",
        "\n",
        "# ---------------------------\n",
        "# 6) categories.csv (Category: id,name)\n",
        "# ---------------------------\n",
        "categories = [{\"id\": cid, \"name\": f\"Category {i}\"} for i, cid in enumerate(category_ids, start=1)]\n",
        "cat_df = pd.DataFrame(categories)\n",
        "cat_path = os.path.join(OUTPUT_DIR, \"categories.csv\")\n",
        "cat_df.to_csv(cat_path, index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# 7) suppliers.csv (Supplier: id,name,contactInfo,address)\n",
        "# ---------------------------\n",
        "suppliers = []\n",
        "for i, sid in enumerate(supplier_ids, start=1):\n",
        "    suppliers.append({\n",
        "        \"id\": sid,\n",
        "        \"name\": f\"Supplier {i}\",\n",
        "        \"contactInfo\": f\"supplier{i}@demo.com | {fake.phone_number()}\",\n",
        "        \"address\": fake.address().replace(\"\\n\", \", \")\n",
        "    })\n",
        "\n",
        "sup_df = pd.DataFrame(suppliers)\n",
        "sup_path = os.path.join(OUTPUT_DIR, \"suppliers.csv\")\n",
        "sup_df.to_csv(sup_path, index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# 8) users.csv (User: id,name,email,password,phoneNumber,address,role,createdAt)\n",
        "#    ✅ IMPORTANT: supplier users are included with SAME IDs as suppliers (SUP*)\n",
        "# ---------------------------\n",
        "users = []\n",
        "\n",
        "# Supplier Users (IDs = SUP1..SUPn)\n",
        "for i, sid in enumerate(supplier_ids, start=1):\n",
        "    uname = f\"supplier{i}\"\n",
        "    users.append({\n",
        "        \"id\": sid,\n",
        "        \"name\": uname,\n",
        "        \"email\": f\"{uname}@demo.com\",\n",
        "        \"password\": DEFAULT_PASSWORD,\n",
        "        \"phoneNumber\": fake.phone_number(),\n",
        "        \"address\": fake.address().replace(\"\\n\", \", \"),\n",
        "        \"role\": \"SUPPLIER\",\n",
        "        \"createdAt\": datetime.utcnow().isoformat()\n",
        "    })\n",
        "\n",
        "# Seller Users (IDs = USR1..USRn)\n",
        "for i, uid in enumerate(seller_user_ids, start=1):\n",
        "    uname = f\"user{i}\"\n",
        "    users.append({\n",
        "        \"id\": uid,\n",
        "        \"name\": uname,\n",
        "        \"email\": f\"{uname}@demo.com\",\n",
        "        \"password\": DEFAULT_PASSWORD,\n",
        "        \"phoneNumber\": fake.phone_number(),\n",
        "        \"address\": fake.address().replace(\"\\n\", \", \"),\n",
        "        \"role\": \"SELLER\",\n",
        "        \"createdAt\": datetime.utcnow().isoformat()\n",
        "    })\n",
        "\n",
        "usr_df = pd.DataFrame(users)\n",
        "usr_path = os.path.join(OUTPUT_DIR, \"users.csv\")\n",
        "usr_df.to_csv(usr_path, index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# 9) products.csv (Product: id,name,categoryId,brand,price,stockQuantity,supplierId,sku,description,reorderLevel,createdAt)\n",
        "#    ✅ supplierId references SUPPLIER USER IDs (SUP*)\n",
        "# ---------------------------\n",
        "brands = [\"Acme\", \"Nova\", \"Orbit\", \"Zenith\", \"Pioneer\", \"Vertex\"]\n",
        "\n",
        "products = []\n",
        "for i, pid in enumerate(product_ids, start=1):\n",
        "    cat = random.choice(category_ids)\n",
        "    sup_user_id = random.choice(supplier_ids)  # supplier user id (SUP*)\n",
        "\n",
        "    price = round(random.uniform(5, 150), 2)\n",
        "    stock = random.randint(20, 200)\n",
        "\n",
        "    products.append({\n",
        "        \"id\": pid,\n",
        "        \"name\": f\"Product {i}\",\n",
        "        \"categoryId\": cat,\n",
        "        \"brand\": random.choice(brands),\n",
        "        \"price\": price,\n",
        "        \"stockQuantity\": stock,\n",
        "        \"supplierId\": sup_user_id,\n",
        "        \"sku\": f\"SKU-{i:04d}\",\n",
        "        \"description\": fake.sentence(nb_words=8),\n",
        "        \"reorderLevel\": random.randint(10, 40),\n",
        "        \"createdAt\": datetime.utcnow().isoformat()\n",
        "    })\n",
        "\n",
        "prod_df = pd.DataFrame(products)\n",
        "prod_path = os.path.join(OUTPUT_DIR, \"products.csv\")\n",
        "prod_df.to_csv(prod_path, index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# 10) transactions.csv (Transaction: id,productId,userId,supplierId,transactionType,totalProducts,totalPrice,discount,promotion,saleDate,status,createdAt)\n",
        "#    ✅ PURCHASE transactions supplierId references SUPPLIER USER IDs (SUP*)\n",
        "# ---------------------------\n",
        "start_date = datetime.fromisoformat(START_DATE)\n",
        "end_date   = datetime.fromisoformat(END_DATE)\n",
        "days = (end_date - start_date).days\n",
        "\n",
        "transactions = []\n",
        "tx_id = 1\n",
        "\n",
        "for d in range(days):\n",
        "    current_date = start_date + timedelta(days=d)\n",
        "    tx_count = random.randint(TX_PER_DAY_MIN, TX_PER_DAY_MAX)\n",
        "\n",
        "    for _ in range(tx_count):\n",
        "        product = random.choice(products)\n",
        "        seller_user = random.choice(seller_user_ids)\n",
        "        supplier_user = random.choice(supplier_ids)\n",
        "\n",
        "        tx_type = random.choices([\"SALE\", \"PURCHASE\"], weights=[0.75, 0.25])[0]\n",
        "        qty = random.randint(1, 8) if tx_type == \"SALE\" else random.randint(5, 25)\n",
        "\n",
        "        unit_price = float(product[\"price\"])\n",
        "        total_price = round(unit_price * qty, 2)\n",
        "\n",
        "        transactions.append({\n",
        "            \"id\": f\"TX{tx_id}\",\n",
        "            \"productId\": product[\"id\"],\n",
        "            \"userId\": seller_user,\n",
        "            \"supplierId\": supplier_user if tx_type == \"PURCHASE\" else \"\",\n",
        "            \"transactionType\": tx_type,\n",
        "            \"totalProducts\": qty,\n",
        "            \"totalPrice\": total_price,\n",
        "            \"discount\": 0.0,\n",
        "            \"promotion\": False,\n",
        "            \"saleDate\": current_date.date().isoformat(),\n",
        "            \"status\": \"RECEIVED\" if tx_type == \"PURCHASE\" else \"COMPLETED\",\n",
        "            \"createdAt\": datetime.utcnow().isoformat()\n",
        "        })\n",
        "        tx_id += 1\n",
        "\n",
        "tx_df = pd.DataFrame(transactions)\n",
        "tx_path = os.path.join(OUTPUT_DIR, \"transactions.csv\")\n",
        "tx_df.to_csv(tx_path, index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# 11) SUMMARY\n",
        "# ---------------------------\n",
        "print(\"\\n✅ CSV files generated successfully:\")\n",
        "print(\" -\", cat_path)\n",
        "print(\" -\", sup_path)\n",
        "print(\" -\", usr_path)\n",
        "print(\" -\", prod_path)\n",
        "print(\" -\", tx_path)\n",
        "\n",
        "print(\"\\nRows generated:\")\n",
        "print(\"categories:\", len(cat_df))\n",
        "print(\"suppliers:\", len(sup_df))\n",
        "print(\"users:\", len(usr_df), \"(includes suppliers + sellers)\")\n",
        "print(\"products:\", len(prod_df))\n",
        "print(\"transactions:\", len(tx_df))\n",
        "\n",
        "# ---------------------------\n",
        "# 12) ZIP + DOWNLOAD\n",
        "# ---------------------------\n",
        "!zip -r generated_csv.zip {OUTPUT_DIR} > /dev/null\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"generated_csv.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CbEmJ5WUEHay"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}